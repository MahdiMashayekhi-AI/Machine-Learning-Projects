# -*- coding: utf-8 -*-
"""Rossmann_Sales_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eht3lMmVA4NIqEwMUbqCgXE9pg6hb0Hp

# Rossmann Store Sales Prediction

## Importing the libraries
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
sns.set_style("whitegrid")

"""## Importing the dataset

---
We will load the dataset from Kaggle website and use with api of the Kaggle.
"""

from google.colab import files
files.upload()

# Install Kaggle api and make directory for it!
!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

# Commented out IPython magic to ensure Python compatibility.
# Making the directory for dataset
!mkdir dataset
# %cd dataset

# Searching for dataset in Kaggle website
!kaggle datasets list -s rossmann-store-sales

# Commented out IPython magic to ensure Python compatibility.
# Downloading the dataset
!kaggle competitions download -c rossmann-store-sales
# %cd ..

# Unzipping downloaded files and removing unusable files
!unzip dataset/rossmann-store-sales.zip -d dataset
!rm dataset/rossmann-store-sales.zip
!rm dataset/sample_submission.csv

"""## Exploratory Data Analysis (EDA)"""

data = pd.read_csv('dataset/train.csv')

data.head(20)

data.info()

print("There are {} missing values in the data.".format(data.isna().sum()))

sns.histplot(data['Sales'], kde=True)
plt.title('Distribution of Sales')
plt.xlabel('Sales')
plt.ylabel('Frequency')
plt.show()

sns.histplot(data['Date'], bins=30, kde=True)
plt.title('Distribution of Date')
plt.xlabel('Date')
plt.ylabel('Frequency')
plt.show()

sns.lineplot(x='Date', y='Sales', data=data, estimator='mean', errorbar=None)
plt.title('Sales Over Time')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.show()

"""## Preprocessing"""

data['Date'] = pd.to_datetime(data['Date'])
data['StateHoliday'] = pd.to_numeric(data['StateHoliday'], errors='coerce')
print(data['Date'].dtype)
print(data['StateHoliday'].dtype)

data.dropna(subset=['StateHoliday'], inplace=True)

data['Day'] = data['Date'].dt.day
data['Month'] = data['Date'].dt.month
data['Year'] = data['Date'].dt.year

data.head()

required_columns = ['Store', 'Date', 'Year']

try:
    data = data.drop(required_columns, axis=1)
except KeyError:
    pass

data.tail()

X = data.drop(columns=['Sales'])
X_numeric = data.select_dtypes(include=[np.number])
y = data['Sales']

print("Shape of X variable is: {}".format(X.shape))
print("Shape of Y variable is: {}".format(y.shape))

from sklearn.feature_selection import mutual_info_regression

mir = mutual_info_regression(X_numeric, y)
feature_names = X_numeric.columns.tolist()
plt.bar(feature_names, mir)
plt.xticks(rotation=90)
plt.xlabel('Feature Name')
plt.ylabel('Importance of Feature')
plt.title('Important Features')
plt.show()

X.head()

y.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, shuffle=True)

print('Shape of X_train: {}'.format(X_train.shape))
print('Shape of X_test: {}'.format(X_test.shape))
print('Shape of y_train: {}'.format(y_train.shape))
print('Shape of y_test: {}'.format(y_test.shape))

"""## Training the model with Random Forest Regressor"""

from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=1234)
model.fit(X_train, y_train)

"""## Model Evaluation"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'Mean Absolute Error: {mae}')
print(f'R-squared: {round(r2 * 100, 3)}%')

# Display important feature
feature_importances = model.feature_importances_
indices = feature_importances.argsort()[::-1]
num_features = X_train.shape[1]

# Display a limited number of features
plt.bar(range(num_features), feature_importances[indices[:num_features]], align="center")
plt.title("Feature Importances")
plt.xticks(range(num_features), X_train.columns[indices[:num_features]], rotation=45)
plt.xlim([-1, num_features])
plt.show()

"""## Submission for Kaggle  """

submission = pd.DataFrame({'Id': range(1, len(y_pred) + 1), 'Sales': y_pred})
submission.to_csv('submission.csv', index=False)

!kaggle competitions submit -c rossmann-store-sales -f submission.csv -m "This submission contains predictions made using a machine learning model for the Kaggle competition. The model has been trained on a subset of the provided dataset and fine-tuned to make predictions on the test data. "

"""## Saving the model"""

import pickle

with open('model.pkl', 'wb') as f:
  pickle.dump(model, f)