# -*- coding: utf-8 -*-
"""Bike_Demand_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vrV9q4WuncfUtFR2jkBsff3u-XUY37Bq

# Bike Sharing Demand prediction

## Step 0 - Import Libraries
"""

import math
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from matplotlib import style
plt.style.use('seaborn')

"""## Step 1 - Read the data"""

dataset = pd.read_csv('hour.csv')

"""## Step 2 - Prelim Analysis and Feature selection"""

df = dataset.copy()

df.head()

df.tail()

df.shape

df.info()

df.describe().T

df.isnull().sum()

df = df.drop(['index', 'date', 'casual', 'registered'], axis=1)

df.head()

# Create pandas histogram
df.hist(rwidth=0.9)
plt.tight_layout()

"""## Step 3 - Data Visualisation"""

# Visualise the continuous features Vs demand
plt.subplot(2, 2, 1)
plt.title('Temperature Vs Demand')
plt.scatter(df['temp'], df['demand'], s=2, c='g', alpha=0.5)

plt.subplot(2, 2, 2)
plt.title('aTemp Vs Demand')
plt.scatter(df['atemp'], df['demand'], s=2, c='b', alpha=0.5)

plt.subplot(2, 2, 3)
plt.title('Humidity Vs Demand')
plt.scatter(df['humidity'], df['demand'], s=2, c='m', alpha=0.5)

plt.subplot(2, 2, 4)
plt.title('Windspeed Vs Demand')
plt.scatter(df['windspeed'], df['demand'], s=2, c='c', alpha=0.5)

plt.tight_layout()
plt.show()

# Visualise the categorical features
colors = ['g', 'r', 'm', 'b']

plt.subplot(3, 3, 1)
plt.title('Average Demand per Season')
cat_list = df['season'].unique()
cat_avg = df.groupby('season').mean()['demand']
plt.bar(cat_list, cat_avg, color=colors)

plt.subplot(3, 3, 2)
plt.title('Average Demand per month')
cat_list = df['month'].unique()
cat_avg = df.groupby('month').mean()['demand']
plt.bar(cat_list, cat_avg, color=colors)

plt.subplot(3, 3, 3)
plt.title('Average Demand per Holiday')
cat_list = df['holiday'].unique()
cat_avg = df.groupby('holiday').mean()['demand']
plt.bar(cat_list, cat_avg, color=colors)

plt.subplot(3, 3, 4)
plt.title('Average Demand per Weekday')
cat_list = df['weekday'].unique()
cat_avg = df.groupby('weekday').mean()['demand']
plt.bar(cat_list, cat_avg, color=colors)

plt.subplot(3, 3, 5)
plt.title('Average Demand per Year')
cat_list = df['year'].unique()
cat_avg = df.groupby('year').mean()['demand']
plt.bar(cat_list, cat_avg, color=colors)

plt.subplot(3, 3, 6)
plt.title('Average Demand per Hour')
cat_list = df['hour'].unique()
cat_avg = df.groupby('hour').mean()['demand']
plt.bar(cat_list, cat_avg, color=colors)

plt.subplot(3,3,7)
plt.title('Average Demand per Workingday')
cat_list = df['workingday'].unique()
cat_average = df.groupby('workingday').mean()['demand']
plt.bar(cat_list, cat_average, color=colors)

plt.subplot(3,3,8)
plt.title('Average Demand per Weather')
cat_list = df['weather'].unique()
cat_average = df.groupby('weather').mean()['demand']
plt.bar(cat_list, cat_average, color=colors)

plt.tight_layout()
plt.show()

# Check for outliers
df['demand'].describe()

df['demand'].quantile([0.05, 0.1, 0.15, 0.9, 0.95, 0.99])

"""## Step 4 - Check Multiple Linear Regression Assumptions"""

# Linearity using correlation coefficient matrix using corr
correlation = df[['temp', 'atemp', 'humidity', 'windspeed',	'demand']].corr()
correlation

plt.title('Correlation Heatmap')
sns.heatmap(correlation, cmap="YlGnBu", annot=True)
plt.show()

"""## Step 5 - Drop irrelevant features"""

df = df.drop(['weekday', 'year', 'workingday', 'atemp', 'windspeed'], axis=1)

df.head()

df.shape

# Autocorrelation of demand using acor
dff1 = pd.to_numeric(df['demand'], downcast='float')
plt.title('Autocorrelation of demand')
plt.acorr(dff1, maxlags=12)
plt.show()

"""## Step 6 - Create/Modify new features"""

# Log Normalise the feature 'Demand'
df1 = df['demand']
df2 = np.log(df1)

plt.figure()
df.hist(rwidth=0.9, bins=20)
plt.tight_layout()

plt.figure()
df2.hist(rwidth=0.9, bins=20)
plt.tight_layout()

df['demand']

df['demand'] = np.log(df['demand'])
df['demand']

# Solve the problem of Autocorrelation
# Shift the demand by 3 lags
t_1 = df['demand'].shift(+1).to_frame()
t_1.columns = ['t-1']

t_2 = df['demand'].shift(+2).to_frame()
t_2.columns = ['t-2']

t_3 = df['demand'].shift(+3).to_frame()
t_3.columns = ['t-3']

df_lag = pd.concat([df, t_1, t_2, t_3], axis=1)
df_lag = df_lag.dropna()

df_lag.head()

"""## Step 7 - Create Dummy Variables and drop first to avoid dummy variables trap"""

# - season
# - holiday
# - weather
# - month
# - hour
#
# Using get_dummies
df_lag.dtypes

df_lag['season'] = df_lag['season'].astype('category')
df_lag['month'] = df_lag['month'].astype('category')
df_lag['hour'] = df_lag['hour'].astype('category')
df_lag['holiday'] = df_lag['holiday'].astype('category')
df_lag['weather'] = df_lag['weather'].astype('category')

df_lag.dtypes

df_lag = pd.get_dummies(df_lag, drop_first=True)

df_lag.head()

X = df_lag.drop(['demand'], axis=1)
y = df_lag[['demand']]

X.shape

y.shape

"""## Step 8 - Create Train and test split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

X_train.shape

X_test.shape

y_train.shape

y_test.shape

"""## Step 9 - Fit and Score the model"""

# Linear Regression
from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)

r2_train = model.score(X_train, y_train)
r2_test = model.score(X_test, y_test)

print(f'R2 Train Score: {round(r2_train * 100, 2)} %')
print(f'R2 Test Score: {round(r2_test * 100, 2)} %')

# Create Y Predictions
y_pred = model.predict(X_test)
y_pred

from sklearn.metrics import mean_squared_error

rmse = math.sqrt(mean_squared_error(y_test, y_pred))
print(f'RMSE : {round(rmse * 100, 2)} %')